\section{Einführung}
\subsection{Gleichungssystem lösen}
\subsubsection{Gauss-Jordan Verfahren}\label{gaussjordan}
Um mehrere Gleichungssysteme simultan zu lösen, müssen die Koeffizientenmatrizen \textit{gleich} sein:
\[A\textcolor{red}{x} = r_1 \qquad A\textcolor{red}{x} = r_2\]
In Gausstableau lösen:
\[
\begin{array}{|c|cc|}
	\hline
	  & &  \\
    A & r_1 & r_2 \\
      & &   \\
	\hline
\end{array}
\xrightarrow{Gauss}
\begin{array}{|ccc|cc|}
	\hline
	1 & 0 & 0 & & \\
	0 & 1 & 0 & \textcolor{red}{x_1} & \textcolor{red}{x_2} \\
	0 & 0 & 1 &  & \\
	\hline
\end{array}
\]

\subsubsection{Cramersche Regel}
Mit der Cramersche-Regel können direkt einzelne Lösungen berechnet werden.

\noindent Dazu Lösungs-Vektor in entsprechende Spalte der Variable einsetzen und Verhältnis der Determinanten bilden.

\noindent Beispiel
\[
	\begin{vmatrix}
		1x_1 + 2x_2 &= \textcolor{red}{3} \\
		4x_1 + 5x_2 &= \textcolor{red}{6}
	\end{vmatrix} \Rightarrow
	\left(\begin{array}{cc|c}
		1 & 2 & \textcolor{red}{3} \\
		4 & 5 & \textcolor{red}{6} 
	\end{array}\right)
\]

\[
	x_1 = \frac{\det(A_1)}{\det(A)} = \frac{
			\begin{vmatrix}
				\textcolor{red}{3} & 2 \\
				\textcolor{red}{6} & 5
			\end{vmatrix}
		  }{
  			  \begin{vmatrix}
			  	1 & 2 \\
			  	4 & 5
			  \end{vmatrix}
	      }
       =
       \frac{3}{-3}
       = \underline{-1}
\]

\[
	x_2 = \frac{\det(A_2)}{\det(A)} = \frac{
		\begin{vmatrix}
			1 & \textcolor{red}{3} \\
			4 & \textcolor{red}{6}
		\end{vmatrix}
	}{
		\begin{vmatrix}
			1 & 2 \\
			4 & 5
		\end{vmatrix}
	}
	=
	\frac{-6}{-3}
	= \underline{2}
\]


\subsection{Inverse Matrix}\label{inversematrix}
Matrix $A$ ist genau dann invertierbar, wenn $\det(A) \neq 0$. 

\[
\begin{array}{|c|c|} \hline A & E \\ \hline \end{array} \xrightarrow{Gauss}
\begin{array}{|c|c|} \hline E & A^{-1} \\ \hline \end{array} 
\]

\noindent
Spezial-Fall (2x2):
\[
	A = \begin{pmatrix}
		a & b \\
		c & d \\
	\end{pmatrix}
   \Rightarrow 
    A^{-1} =\frac{1}{det(A)}
	\begin{pmatrix}
		d & -b \\
		-c & a \\
	\end{pmatrix}
\]

\noindent
Spezial-Fall (3x3):

\[A=\begin{pmatrix} 
	a & b & c \\
	d & e & f \\
	g & h & i \\
\end{pmatrix}  \Rightarrow \] \[A^{-1} = \frac{1}{det(A)}
\begin{pmatrix} 
	+\underbrace{\left|\begin{array}{rr} e & f \\ h & i \\ \end{array}\right|}_{det(A_{11})} &
	-\underbrace{\left|\begin{array}{rr} b & c \\ h & i \\ \end{array}\right|}_{det(A_{21})} &
	+\underbrace{\left|\begin{array}{rr} b & c \\ e & f \\ \end{array}\right|}_{det(A_{31})} \\
	
	-\underbrace{\left|\begin{array}{rr} d & f \\ g & i \\ \end{array}\right|}_{det(A_{12})} &
	+\underbrace{\left|\begin{array}{rr} a & c \\ g & i \\ \end{array}\right|}_{det(A_{22})} &
	-\underbrace{\left|\begin{array}{rr} a & c \\ d & f \\ \end{array}\right|}_{det(A_{32})} \\
	
	+\underbrace{\left|\begin{array}{rr} d & e \\ g & h \\ \end{array}\right|}_{det(A_{13})} &
	-\underbrace{\left|\begin{array}{rr} a & b \\ g & h \\ \end{array}\right|}_{det(A_{23})} &
	+\underbrace{\left|\begin{array}{rr} a & b \\ d & e \\ \end{array}\right|}_{det(A_{33})} \\
\end{pmatrix}\]

\subsection{Transponierte Matrix}\label{transposematrix}
Zeilen und Spalten vertauschen.

Beispiel:
\[
	A_{3,3} = \begin{pmatrix}
		\textcolor{red}{5} & \textcolor{red}{7} & \textcolor{red}{3} \\
		8 & 16 & 9 \\
		22 & 1 & 7 \\
	\end{pmatrix}
	\qquad
	A^{T}_{3,3} = \begin{pmatrix}
		\textcolor{red}{5} & 8 & 22 \\
		\textcolor{red}{7} & 16 & 1 \\
		\textcolor{red}{3} & 9 & 7 \\
	\end{pmatrix}
\]

\subsubsection{Orthogonale Matrix}\label{orthogonalmatrix}
Orthogonale Matrizen stehen Zeilen oder Spaltenweise Senkrechte zu einander. Eine Matrix $M$ ist genau dann orthogonal, wenn gilt: \[M^{-1} = M^T \qquad oder \qquad MM^T = E\]

\noindent Siehe auch \verweiseref{inversematrix}, \verweiseref{transposematrix}

\subsection{Lösungsmenge}
Die Gleichung $ax = b$ hat je nach $a$ und $b$ verschiedene Lösungs-Typen:\\ 
Bei $a \neq 0$ gibt es genau eine Lösung, dies ist der \textbf{Regulär-Fall}. Wenn $a = 0 \text{ und } b \neq 0$, gibt der \textbf{Singuläre-Fall} keine Lösung, jedoch bei $b = 0$, dann gibt es $\infty$-Lösungen. Regulär und singulär kann mittels \textit{\verweiseref{detmenge}} ermittelt werden.
\\ \\
\noindent\textbf{Inhomogen} ist das Gleichungssystem wenn $b \neq 0$, \textbf{Homogen} bei $b = 0$.
\\ \\
\noindent Lösungsmenge eines inhomogenen Gleichungssystems:
\[
\xrightarrow{Gauss}
\begin{array}{|ccc|c|}
	\hline
	1 & 0 & -5 & 1 \\
	0 & 1 & 3 & 2  \\
	0 & 0 & 0 & 0 \\
	\hline
\end{array}
\] 
\[
\mathbb{L} = \left\{
	\underbrace{
		\begin{pmatrix} 
			1 \\ 2 \\ 0 
		\end{pmatrix}
	}_{\text{Lös.Vek}}
	+
	\underbrace{
		z \begin{pmatrix} 
			5 \\ -3 \\ 1
		\end{pmatrix}
	}_{\text{Frei.Vek}}
	| z \in \mathbb{R}
\right\}
\]

\noindent\textit{Hinweis}: bei den frei wählbaren Variablen müssen die Vorzeichen getauscht und in entsprechendem Vektor eine $1$ hinzugefügt werden.

\subsection{Lineare Abhängigkeit}
Bei lineare Abhängigkeiten entstehen beim Gauss-Algorithmus Null-Zeilen. Diese sind also Kombinationen aus vorherigen Zeilen/Spalten. Der \textbf{Rang} einer Matrix ist die Anzahl linear unabhängiger Zeilen. Mittels den Koeffizienten $\lambda_i$ der Matrix $A$ kann die Lösungsmenge durch $A^T = 0$ gesteuert werden:

\noindent Beispiel Koeffizienten Bestimmen:
\[
A = \begin{array}{|ccc|}
	\hline
	x_1 & x_2 & x_3 \\
	\hline
	1 & 2 & 3 \\
	4 & 5 & 6 \\
	7 & 8 & 9 \\
	\hline
\end{array} \xrightarrow{Gauss} \text{Null-Zeile}
\]

\[
A^T \Rightarrow
	\begin{array}{|ccc|c|}
		\hline
		\lambda_1 & \lambda_2 & \lambda_3 & \\
		\hline
		1 & 4 & 7 & 0 \\
		2 & 5 & 8 & 0 \\
		3 & 6 & 9 & 0 \\
		\hline
	\end{array}
	\xrightarrow{Gauss}
	\begin{array}{|ccc|c|}
		\hline
		\lambda_1 & \lambda_2 & \lambda_3 & \\
		\hline
		1 & 0 & -1 & 0 \\
		0 & 1 & 2 & 0 \\
		0 & 0 & 0 & 0 \\
		\hline
	\end{array}
\]
Es gibt $\infty$-Lösungen, eine zB bei $\lambda_3 = 1; \lambda_2 = -2; \lambda_1 = 1$.

\subsection{Algebra mit Matrizen}
\begin{itemize}[nosep]
	\item $(A \cdot B)^{-1} = B^{-1} \cdot A^{-1}$
	\item $(A^T)^{-1} = (A^{-1})^T$
	\item $(A^{-1})^{-1} = A$
	\item $(k \cdot A)^{-1} = k^{-1} \cdot A^{-1}$ (Skalar $k \neq 0$)
	\item $(Ax)^T = x^TA^T$
	\item $AA^{-1} = E$
	\item $A(\lambda x) = \lambda(Ax)$
	\item $A(x + y) = Ax + Ay$
\end{itemize}
~\\
\noindent\textbf{Achtung}: Beim Multiplizieren von Matrizen ist die Reihenfolge zwingend! zB wird $\textcolor{blue}{T}$ auf beiden Seiten \underline{Rechts} hinzugefügt!
\begin{align*}
	D &= TAT^{-1}  &| \quad \cdot \textcolor{red}{T^{-1}}\\
	\textcolor{red}{T^{-1}}D &= \textcolor{red}{T^{-1}}TAT^{-1}  &| \quad \cdot \textcolor{blue}{T}\\
	T^{-1}D\textcolor{blue}{T} &= \underbrace{T^{-1}T}_{E} A \underbrace{T^{-1}\textcolor{blue}{T}}_{E} = A
\end{align*}
